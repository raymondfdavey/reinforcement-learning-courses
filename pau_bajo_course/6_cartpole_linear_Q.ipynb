{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARTPOLE PROBLEM\n",
    "\n",
    "A pole is attached to a cart with an un-actuated joint. And your goal is to move the cart position, left and right, to prevent the pole from falling.\n",
    "\n",
    "**<ins>Why this problem?</ins>**\n",
    "\n",
    "So far in the course, we have used classical Reinforcement Learning algorithms, Q-learning (part 2), and SARSA (part 3) in a discrete/tabular environment.\n",
    "\n",
    "Today’s problem is slightly more complex because its state space is *too large to be discretized*. Instead, we need to level up our game and use more powerful RL algorithms.\n",
    "\n",
    "We will use `parametric Q-learning,` a technique that combines the classic Q-learning we saw in part 2, with parametric approximations, either linear ones (here in part 4) or a more complex one like neural nets (in part 5).\n",
    "\n",
    "Parametric Q-learning using neural nets (aka Deep Q-learning) lies behind many recent breakthroughs in Reinforcement Learning, like the famous Atari game player by DeepMind.\n",
    "\n",
    "Let’s get familiar with the specifics of this environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import gym\n",
    "\n",
    "# LOAD ENVIRONMENT\n",
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x111092a70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SHOW A FRAME\n",
    "env.reset()\n",
    "frame = env.render(mode='rgb_array')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.axes.yaxis.set_visible(False)\n",
    "min_x = env.observation_space.low[0]\n",
    "max_x = env.observation_space.high[0]\n",
    "ax.imshow(frame, extent=[min_x, max_x, 0, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENVIRONMENT, ACTIONS, STATES, REWARDS\n",
    "\n",
    "![](cartpole_image.jpeg)\n",
    "\n",
    "### <ins>State</ins>\n",
    "\n",
    "State is represented by 4 values shown above:\n",
    "\n",
    " - the cart position **x** from `-2.4` to `2.4`\n",
    " - the cart velocity **v**\n",
    " - the pole angle $\\theta$ with respect to the vertical. From `-12` to `12` degrees (`-0.21` to `0.21` in radians)\n",
    " - the pole angular velocity $\\omega$. This is the rate of change of $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cart position from -4.80 to 4.80\n",
      "Cart velocity from -3.40E+38 to 3.40E+38\n",
      "Angle from -0.42 to 0.42\n",
      "Angular velocity from -3.40E+38 to 3.40E+38\n"
     ]
    }
   ],
   "source": [
    "# The state on observation space looks different though...\n",
    "x_min, v_min, angle_min, angular_v_min = env.observation_space.low\n",
    "x_max, v_max, angle_max, angular_v_max = env.observation_space.high\n",
    "\n",
    "print(f'Cart position from {x_min:.2f} to {x_max:.2f}')\n",
    "print(f'Cart velocity from {v_min:.2E} to {v_max:.2E}')\n",
    "print(f'Angle from {angle_min:.2f} to {angle_max:.2f}')\n",
    "print(f'Angular velocity from {angular_v_min:.2E} to {angular_v_max:.2E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the OpenAI gym interval variables `env.observation_space.low` and `env.observation_space.high` you will see that these 2 numbers seem to be arbitrarily large or small and their intervals do NOT match what we have written above.\n",
    "\n",
    "In practice, this is not true. Both **v** and $\\omega$ have narrower intervals, but this is something you cannot directly read from the env object. You can only observe their real ranges as your agent explores the environment.\n",
    "\n",
    "This is important because the models we will use today, and in part 5, work best with **normalized inputs**. In this case, **normalized states**. And to *normalize a number* you need to know first its max and min values. These 2 values for **v** and $\\omega$ cannot be read from the env.observation_space . You need to estimate them using a bit of exploration.\n",
    "\n",
    "<ins>DO NOT BLINDLY TAKE THE VALUES IN `env.observation_space` AS THE REAL RANGES FOR EACH STATE</ins>\n",
    "\n",
    "### <ins>Episode starts and ends</ins>\n",
    "\n",
    "An episode terminates when either:\n",
    "\n",
    " - the cart goes beyond the limits: `x > 2.4` or x `< -2.4`\n",
    " - the pole is too far from the vertical: `θ > 12` degrees or `θ < -12` degrees.\n",
    " - or we reached the maximum number of episodes steps, `500`. In this case, the agent perfectly solved the episode.\n",
    "\n",
    "The starting state is sampled randomly from the interval `[-0.05, 0.05]` for each state. Sometimes, the starting position is so close to balance that the episode is easy. Other times, the starting position is so off-balance that the episode is much harder to solve, and sometimes even impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <ins>Actions</ins>\n",
    "\n",
    "What about the **actions** our agent can perform?\n",
    " - 0 : Push the cart to the left.\n",
    " - 1 : Push the cart to the right.\n",
    "\n",
    "### <ins>Rewards</ins>\n",
    "The reward is `+1` for every step taken. This means that the longer the agent keeps the pole standing, the higher the cumulative reward.\n",
    "\n",
    "### <ins>Random Agent Baseline</ins>\n",
    "\n",
    "As usual, we use a `RandomAgent` to establish a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List, Callable, Union, Optional\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class RandomAgent:\n",
    "    \"\"\"\n",
    "    This taxi driver selects actions randomly.\n",
    "    You better not get into this taxi!\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def act(self, state: np.array, epsilon: float = None) -> int:\n",
    "        \"\"\"\n",
    "        No input arguments to this function.\n",
    "        The agent does not consider the state of the environment when deciding\n",
    "        what to do next.\n",
    "        \"\"\"\n",
    "        return self.env.action_space.sample()\n",
    "\n",
    "def evaluate(\n",
    "    agent,\n",
    "    env,\n",
    "    n_episodes: int,\n",
    "    epsilon: Optional[float] = None,\n",
    "    seed: Optional[int] = 0,\n",
    ") -> Tuple[List, List]:\n",
    "\n",
    "    # output metrics\n",
    "    reward_per_episode = []\n",
    "    steps_per_episode = []\n",
    "\n",
    "    for i in tqdm(range(0, n_episodes)):\n",
    "\n",
    "        state = env.reset()\n",
    "        rewards = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "\n",
    "            action = agent.act(state, epsilon=epsilon)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            rewards += reward\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "\n",
    "        reward_per_episode.append(rewards)\n",
    "        steps_per_episode.append(steps)\n",
    "\n",
    "    return reward_per_episode, steps_per_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1521.83it/s]\n"
     ]
    }
   ],
   "source": [
    "agent = RandomAgent(env)\n",
    "n_episodes = 1000\n",
    "rewards, steps = evaluate(agent, env, n_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAEICAYAAACOHvrxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYmklEQVR4nO3de7SddX3n8fcHgnLxwu00Q4kxWBkYRuXiEXFhrYJULArpVCkutZGhzXSmjlo7U4N1FadrZlZctSK21mkUJVoVEVGYYm1jRLQXwQStXKITxCBgQlJKBNERo9/5Yz8ZzgonZOfkPL9zzs77tdZZ+7nu53seHpJPfr/f/u1UFZIkSerfPjNdgCRJ0t7C4CVJktSIwUuSJKkRg5ckSVIjBi9JkqRGDF6SJEmNGLwkaQqSvC7J3810HZLmFoOXpFkpyYYkP0rygySbklyW5AkzXZck7QmDl6TZ7OVV9QTgBOBE4MKZKCLJvJm4rqTRY/CSNOtV1SbgbxgEMJKckuQfkmxN8k9JXthtf1GSm7efl2RVkq9OWP9yksXd8rIk307yYJLbkvzqhONel+Tvk1yc5D7g7UkOS3JNkgeS3Aj8woTj0x27udt/c5Jn9HlPJM1N/itO0qyXZAHwUuALSY4ErgVeC3wOOB34VJJjga8ARyc5HPg+8CxgW5InAtuAceDL3dt+G/hFYBPwSuAvkzy9qjZ2+58LXA7MB/YDPgT8X+AI4CgGQfA73bG/DLwA+NfddY8Ftk77jZA059niJWk2+0ySB4G7gM3ARcBrgM9W1Wer6mdVtQpYA/xKVf0I+CqDEPRs4J+AvwdOBU4B1lfVfQBV9cmq+l73Hp8A1gMnT7j296rqT6tqG/Aw8GvAH1bVQ1V1C7BywrE/AZ7IIHClqtZNCHCS9P8ZvCTNZour6onACxmEmsOBpwKv7LoZtybZCjyfQUsUwPXd8S/olr8I/FL3c/32N07yG0m+PuE9ntG9/3Z3TVgeY9BDMHHbndsXquoLwJ8B7wU2J1mR5El78otLGk0GL0mzXlVdD1wGvJNB+PlIVR084eegqlreHb5j8LqeHYJXkqcC7wdeDxxWVQcDtwCZeNkJy1sYdFU+ZcK2hTvU+J6qejZwHIMux/+6Z7+1pFFk8JI0V7wbOAP4B+DlSV6SZN8k+yd5YTcOjG7/MQy6DW+sqlsZtJI9F/hSd8xBDILVFoAk5zNo8ZpUVf0UuIrBIPsDkxwHLNm+P8lzkjw3yX7AQwzGgv1smn5vSSPE4CVpTqiqLcCHgTcA5wBvZRCc7mLQurRPd9xDwE3ArVX1cHf6PwJ3VtXm7pjbgD/ptt8LPJPBWLDH8nrgCQwG41/GYLD9dk9i0IJ2P4MuyPuAP57yLytpZKWqdn2UJEmS9pgtXpIkSY0YvCRJkhoxeEmSJDVi8JIkSWpkTnxl0OGHH16LFi2a6TIkSZJ2ae3atf9cVWOT7ZsTwWvRokWsWbNmpsuQJEnapSR37myfXY2SJEmNGLwkSZIaMXhJkiQ1YvCSJElqxOAlSZLUiMFLkiSpEYOXJElSIwYvSZKkRgxekiRJjcyJmeu1exYtu/ZR2zYsP2sGKpEkSRPZ4iVJktSIwUuSJKkRg5ckSVIjBi9JkqRGDF6SJEmN9Bq8kvxukluT3JLk40n2T3JUkhuS3J7kE0ke12cNkiRJs0VvwSvJkcAbgPGqegawL3Ae8A7g4qp6OnA/cEFfNUiSJM0mfXc1zgMOSDIPOBDYCJwGXNntXwks7rkGSZKkWaG34FVV9wDvBL7LIHB9H1gLbK2qbd1hdwNH9lWDJEnSbNJnV+MhwDnAUcDPAwcBZ+7G+UuTrEmyZsuWLT1VKUmS1E6fXY0vBr5TVVuq6ifAVcCpwMFd1yPAAuCeyU6uqhVVNV5V42NjYz2WKUmS1Eafweu7wClJDkwS4HTgNuA64BXdMUuAq3usQZIkadboc4zXDQwG0d8E3NxdawXwFuDNSW4HDgMu7asGSZKk2WTerg+Zuqq6CLhoh813ACf3eV1JkqTZyJnrJUmSGjF4SZIkNWLwkiRJasTgJUmS1IjBS5IkqRGDlyRJUiMGL0mSpEYMXpIkSY0YvCRJkhoxeEmSJDVi8JIkSWrE4CVJktSIwUuSJKkRg5ckSVIjBi9JkqRGDF6SJEmN9Ba8khyT5OsTfh5I8qYkhyZZlWR993pIXzVIkiTNJr0Fr6r6VlWdUFUnAM8Gfgh8GlgGrK6qo4HV3bokSdLIa9XVeDrw7aq6EzgHWNltXwksblSDJEnSjGoVvM4DPt4tz6+qjd3yJmD+ZCckWZpkTZI1W7ZsaVGjJElSr3oPXkkeB5wNfHLHfVVVQE12XlWtqKrxqhofGxvruUpJkqT+tWjxeilwU1Xd263fm+QIgO51c4MaJEmSZlyL4PUqHulmBLgGWNItLwGublCDJEnSjOs1eCU5CDgDuGrC5uXAGUnWAy/u1iVJkkbevD7fvKoeAg7bYdt9DD7lKEmStFdx5npJkqRGDF6SJEmNGLwkSZIaMXhJkiQ10uvgej3aomXXPmrbhuVnzUAlkiSpNVu8JEmSGjF4SZIkNWJX4yxll6QkSaPHFi9JkqRGDF6SJEmNGLwkSZIaMXhJkiQ1YvCSJElqxOAlSZLUiNNJ9GSy6SCm41hJkjR32eIlSZLUSK/BK8nBSa5M8s0k65I8L8mhSVYlWd+9HtJnDZIkSbNF3y1elwCfq6pjgeOBdcAyYHVVHQ2s7tYlSZJGXm/BK8mTgRcAlwJU1cNVtRU4B1jZHbYSWNxXDZIkSbNJn4PrjwK2AB9KcjywFngjML+qNnbHbALmT3ZykqXAUoCFCxf2WOaec3C8JEkaRp9djfOAk4D3VdWJwEPs0K1YVQXUZCdX1YqqGq+q8bGxsR7LlCRJaqPP4HU3cHdV3dCtX8kgiN2b5AiA7nVzjzVIkiTNGr0Fr6raBNyV5Jhu0+nAbcA1wJJu2xLg6r5qkCRJmk36nkD1PwMfTfI44A7gfAZh74okFwB3Auf2XIMkSdKs0GvwqqqvA+OT7Dq9z+tKkiTNRs5cL0mS1IjBS5IkqRGDlyRJUiMGL0mSpEYMXpIkSY0YvCRJkhrpex6vkeP3MkqSpKmyxUuSJKkRg5ckSVIjBi9JkqRGhgpeSZ7ZdyGSJEmjbtgWrz9PcmOS/5Tkyb1WJEmSNKKGCl5V9YvAq4GnAGuTfCzJGb1WJkmSNGKGHuNVVeuBtwFvAX4JeE+Sbyb5d30VJ0mSNEqGHeP1rCQXA+uA04CXV9W/6ZYv7rE+SZKkkTHsBKp/CnwAeGtV/Wj7xqr6XpK37eykJBuAB4GfAtuqajzJocAngEXABuDcqrp/StVLkiTNIcN2NZ4FfGx76EqyT5IDAarqI7s490VVdUJVjXfry4DVVXU0sLpblyRJGnnDBq/PAwdMWD+w2zYV5wAru+WVwOIpvo8kSdKcMmzw2r+qfrB9pVs+cIjzCvjbJGuTLO22za+qjd3yJmD+0NVKkiTNYcOO8XooyUlVdRNAkmcDP9rFOQDPr6p7kvwcsCrJNyfurKpKUpOd2AW1pQALFy4cskxJkqTZa9jg9Sbgk0m+BwT4V8Cv7+qkqrqne92c5NPAycC9SY6oqo1JjgA27+TcFcAKgPHx8UnDmSRJ0lwyVPCqqq8mORY4ptv0rar6yWOdk+QgYJ+qerBb/mXgj4BrgCXA8u716qkWL0mSNJcM2+IF8BwGU0DMA05KQlV9+DGOnw98Osn263ysqj6X5KvAFUkuAO4Ezp1S5ZIkSXPMUMEryUeAXwC+zmBOLhgMnN9p8KqqO4DjJ9l+H3D67hYqWLTs2kdt27D8rBmoRJIkTcWwLV7jwHFV5VgrSZKkKRp2OolbGAyolyRJ0hQN2+J1OHBbkhuBH2/fWFVn91LVDLAbT5Ik9W3Y4PX2PouQJEnaGww7ncT1SZ4KHF1Vn+++p3HffkuTJEkaLUON8UryW8CVwF90m44EPtNTTZIkSSNp2MH1vwOcCjwAUFXrgZ/rqyhJkqRRNGzw+nFVPbx9Jck8BvN4SZIkaUjDBq/rk7wVOCDJGcAngf/dX1mSJEmjZ9jgtQzYAtwM/Afgs8Db+ipKkiRpFA37qcafAe/vfiRJkjQFw35X43eYZExXVT1t2iuSJEkaUbvzXY3b7Q+8Ejh0+suRJEkaXUON8aqq+yb83FNV7wb8Ph1JkqTdMGxX40kTVvdh0AI2bGuZJEmSGD48/cmE5W3ABuDcaa9GkiRphA37qcYXTfUCSfYF1gD3VNXLkhwFXA4cBqwFXjtxclZJkqRRNWxX45sfa39Vvesxdr8RWAc8qVt/B3BxVV2e5H8BFwDvG6YOSZKkuWzYCVTHgf/I4MuxjwR+GzgJeGL3M6kkCxgMwv9Atx7gNAZfuA2wElg8hbolSZLmnGHHeC0ATqqqBwGSvB24tqpes4vz3g38Po+Es8OArVW1rVu/m0GQe5QkS4GlAAsXLhyyzL3PomXXznQJkiRpSMO2eM0HJo7DerjbtlNJXgZsrqq1UymsqlZU1XhVjY+NjU3lLSRJkmaVYVu8PgzcmOTT3fpiBt2Ej+VU4Owkv8Jg0tUnAZcAByeZ17V6LQDu2e2qJUmS5qBhJ1D9H8D5wP3dz/lV9T93cc6FVbWgqhYB5wFfqKpXA9cBr+gOWwJcPcXaJUmS5pRhuxoBDgQeqKpLgLu7aSGm4i3Am5PczmDM16VTfB9JkqQ5ZdjpJC5i8MnGY4APAfsBf8mgO3GXquqLwBe75TuAk3e/1PYcuC5JkqbTsC1evwqcDTwEUFXf4zGmkZAkSdKjDRu8Hq6qAgogyUH9lSRJkjSahg1eVyT5CwafSPwt4PPA+/srS5IkafTscoxXN9v8J4BjgQcYjPP6w6pa1XNtkiRJI2WXwauqKslnq+qZgGFLkiRpiobtarwpyXN6rUSSJGnEDTtz/XOB1yTZwOCTjWHQGPasvgqTJEkaNY8ZvJIsrKrvAi9pVI8kSdLI2lWL12eAk6rqziSfqqpfa1CTJEnSSNrVGK9MWH5an4VIkiSNul0Fr9rJsiRJknbTrroaj0/yAIOWrwO6ZXhkcP2Teq1OkiRphDxm8KqqfVsVIkmSNOqGncdLkiRJe8jgJUmS1IjBS5IkqZFhZ67fbUn2B74EPL67zpVVdVGSo4DLgcOAtcBrq+rhvurQwKJl1z5q24blZ81AJZIk7b36bPH6MXBaVR0PnACcmeQU4B3AxVX1dOB+4IIea5AkSZo1egteNfCDbnW/7qeA04Aru+0rgcV91SBJkjSb9NbVCJBkXwbdiU8H3gt8G9haVdu6Q+4GjtzJuUuBpQALFy7ss0ztgt2UkiRNj14H11fVT6vqBGABcDJw7G6cu6KqxqtqfGxsrK8SJUmSmmnyqcaq2gpcBzwPODjJ9pa2BcA9LWqQJEmaab0FryRjSQ7ulg8AzgDWMQhgr+gOWwJc3VcNkiRJs0mfY7yOAFZ247z2Aa6oqr9KchtweZL/DnwNuLTHGiRJkmaN3oJXVX0DOHGS7XcwGO8lSZK0V3HmekmSpEYMXpIkSY0YvCRJkhoxeEmSJDXS68z1mnsmm6VekiRND1u8JEmSGjF4SZIkNWLwkiRJasTgJUmS1IiD6zWrTTbYf8Pys2agEkmS9pwtXpIkSY0YvCRJkhoxeEmSJDVi8JIkSWrE4CVJktRIb8EryVOSXJfktiS3Jnljt/3QJKuSrO9eD+mrBkmSpNmkz+kktgG/V1U3JXkisDbJKuB1wOqqWp5kGbAMeEuPdWgnpvt7GZ36QZKkx9Zbi1dVbayqm7rlB4F1wJHAOcDK7rCVwOK+apAkSZpNmkygmmQRcCJwAzC/qjZ2uzYB83dyzlJgKcDChQsbVKndsSetZTs719YxSdKo631wfZInAJ8C3lRVD0zcV1UF1GTnVdWKqhqvqvGxsbG+y5QkSepdr8EryX4MQtdHq+qqbvO9SY7o9h8BbO6zBkmSpNmiz081BrgUWFdV75qw6xpgSbe8BLi6rxokSZJmkz7HeJ0KvBa4OcnXu21vBZYDVyS5ALgTOLfHGiRJkmaN3oJXVf0dkJ3sPr2v62p2me4pKyRJmsucuV6SJKkRg5ckSVIjBi9JkqRGDF6SJEmNGLwkSZIaMXhJkiQ1YvCSJElqxOAlSZLUiMFLkiSpkT6/MkjqxWSz4W9YftYMVCJJ0u6xxUuSJKkRg5ckSVIjdjVqZLXokrTbU5K0O2zxkiRJasQWL+31bLWSJLVii5ckSVIjvQWvJB9MsjnJLRO2HZpkVZL13eshfV1fkiRptumzxesy4Mwdti0DVlfV0cDqbl2SJGmv0FvwqqovAf+yw+ZzgJXd8kpgcV/XlyRJmm1aD66fX1Ubu+VNwPydHZhkKbAUYOHChQ1K095gsoH0kiS1MmOD66uqgHqM/SuqaryqxsfGxhpWJkmS1I/WweveJEcAdK+bG19fkiRpxrTuarwGWAIs716vbnx9zWJ70g1oF6IkaS7oczqJjwP/CByT5O4kFzAIXGckWQ+8uFuXJEnaK/TW4lVVr9rJrtP7uqY0XZzNXpLUB2eulyRJasTgJUmS1Ihfki0NaboH/8/VrstR+l0kqTVbvCRJkhoxeEmSJDVi8JIkSWrEMV7SLDNTY6gcuyVJ/bPFS5IkqRGDlyRJUiMGL0mSpEYMXpIkSY04uF6ao4YdDN9i0Hyrgfl+AEDSXGeLlyRJUiMGL0mSpEbsapSm2Z58p2PL95zNRun3HfZ32dNu4rnYDTsXa5b2lC1ekiRJjcxIi1eSM4FLgH2BD1TV8pmoQ5pJM9ky1qJFaU8G//dx7ek23b/LbPpvtzvXtoVKs9VsfV6bt3gl2Rd4L/BS4DjgVUmOa12HJElSazPR1XgycHtV3VFVDwOXA+fMQB2SJElNparaXjB5BXBmVf1mt/5a4LlV9fodjlsKLO1WjwG+1bTQue1w4J9nuoi9iPe7Le93e97ztrzfbfVxv59aVWOT7Zi1n2qsqhXAipmuYy5Ksqaqxme6jr2F97st73d73vO2vN9ttb7fM9HVeA/wlAnrC7ptkiRJI20mgtdXgaOTHJXkccB5wDUzUIckSVJTzbsaq2pbktcDf8NgOokPVtWtresYcXbRtuX9bsv73Z73vC3vd1tN73fzwfWSJEl7K2eulyRJasTgJUmS1IjBaw5L8pQk1yW5LcmtSd7YbT80yaok67vXQ2a61lGSZN8kX0vyV936UUluSHJ7kk90HxrRNElycJIrk3wzybokz/MZ70+S3+3+PLklyceT7O8zPr2SfDDJ5iS3TNg26TOdgfd09/4bSU6aucrnpp3c7z/u/kz5RpJPJzl4wr4Lu/v9rSQvme56DF5z2zbg96rqOOAU4He6r19aBqyuqqOB1d26ps8bgXUT1t8BXFxVTwfuBy6YkapG1yXA56rqWOB4BvfeZ7wHSY4E3gCMV9UzGHwA6jx8xqfbZcCZO2zb2TP9UuDo7mcp8L5GNY6Sy3j0/V4FPKOqngX8H+BCgO7v0POAf9ud8+fdVx1OG4PXHFZVG6vqpm75QQZ/IR3J4CuYVnaHrQQWz0iBIyjJAuAs4APdeoDTgCu7Q7zf0yjJk4EXAJcCVNXDVbUVn/E+zQMOSDIPOBDYiM/4tKqqLwH/ssPmnT3T5wAfroGvAAcnOaJJoSNisvtdVX9bVdu61a8wmFMUBvf78qr6cVV9B7idwVcdThuD14hIsgg4EbgBmF9VG7tdm4D5M1XXCHo38PvAz7r1w4CtE/4HvptB+NX0OArYAnyo6979QJKD8BnvRVXdA7wT+C6DwPV9YC0+4y3s7Jk+ErhrwnHe/+n374G/7pZ7v98GrxGQ5AnAp4A3VdUDE/fVYL4Q5wyZBkleBmyuqrUzXcteZB5wEvC+qjoReIgduhV9xqdPN67oHAaB9+eBg3h0F4165jPdTpI/YDBs56OtrmnwmuOS7McgdH20qq7qNt+7vSm6e908U/WNmFOBs5NsAC5n0P1yCYOm/+2TEfsVWNPrbuDuqrqhW7+SQRDzGe/Hi4HvVNWWqvoJcBWD595nvH87e6b9mr2eJHkd8DLg1fXIpKa932+D1xzWjS+6FFhXVe+asOsaYEm3vAS4unVto6iqLqyqBVW1iMHgyy9U1auB64BXdId5v6dRVW0C7kpyTLfpdOA2fMb78l3glCQHdn++bL/fPuP929kzfQ3wG92nG08Bvj+hS1JTlORMBsNGzq6qH07YdQ1wXpLHJzmKwYcabpzWaztz/dyV5PnAl4GbeWTM0VsZjPO6AlgI3AmcW1U7DuTUHkjyQuC/VNXLkjyNQQvYocDXgNdU1Y9nsLyRkuQEBh9meBxwB3A+g380+oz3IMl/A36dQffL14DfZDDGxWd8miT5OPBC4HDgXuAi4DNM8kx3AfjPGHT5/hA4v6rWzEDZc9ZO7veFwOOB+7rDvlJVv90d/wcMxn1tYzCE5693fM89qsfgJUmS1IZdjZIkSY0YvCRJkhoxeEmSJDVi8JIkSWrE4CVJktSIwUuSJKkRg5ckSVIj/w8lNOzx/sr/ZQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SEE HOW FAR WE GOT\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 4))\n",
    "ax.set_title(\"Rewards\")    \n",
    "pd.Series(rewards).plot(kind='hist', bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward average 22.29, std 12.37\n"
     ]
    }
   ],
   "source": [
    "reward_avg = np.array(rewards).mean()\n",
    "reward_std = np.array(rewards).std()\n",
    "print(f'Reward average {reward_avg:.2f}, std {reward_std:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad hyper-parameters\n",
    "hparams = {\n",
    "    'learning_rate': 9.214691713730938e-05,\n",
    "    'discount_factor': 0.99,\n",
    "    'batch_size': 32,\n",
    "    'memory_size': 10000,\n",
    "    'freq_steps_train': 16,\n",
    "    'freq_steps_update_target': 1000,\n",
    "    'n_steps_warm_up_memory': 1000,\n",
    "    'n_gradient_steps': 1,\n",
    "    'max_grad_norm': 1,\n",
    "    'normalize_state': True,\n",
    "    'epsilon_start': 0.9,\n",
    "    'epsilon_end': 0.08474621504763855,\n",
    "    'steps_epsilon_decay': 100000\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
